\chapter{Temporal Isolation \& \\ Asymmetric Protection}
\label{chap:scheduling}

Mixed-criticality systems at their core require isolation: isolation as strong as that provided by
physically isolated systems, meaning if one system fails it cannot affect another system.  Isolation
can be divided into two categories of resources; physical and temporal. Physical resources include 
devices and memory, where isolation can be achieved using the \gls{MMU} and \IO\glspl{MMU}.
Temporal isolation of resources more complicated, and is our focus in this chapter, where
we survey the relevant literature.
A system is said to provide \emph{temporal isolation} if temporal faults in one task cannot cause
temporal faults in another, independent task. 

However, what does isolation mean in a fully or over-committed system, where there is no slack time 
to schedule? What if there simply is not enough time? One might argue that the method of
over-provisioning systems in order to never face such a scenario is sufficient and should not be
changed. However, in the presence of \gls{SRT} and best-effort tasks which may be low in
criticality, this requirement is too strong. Instead we must explore mechanisms for \emph{asymmetric
protection}, where high criticality tasks can cause a failure in low criticality tasks, but not vice
versa.

Much of the background examined in the previous chapter (\cref{sec:real-time-theory})
made the assumption that tasks would not exceed a declared \gls{WCET} or critical section bound. 
Many existing real-time systems run either one application, or multiple applications of the same
criticality, meaning each application that is running is certified to the same level.  This means
that all applications are trusted: trusted to not crash, and trusted to not overrun their deadlines.
If one application does overrun its deadline or use more processing time that specified by its
\gls{WCET}, guarantees are no longer met. 

Tasks can be untrusted for many reasons including:
\begin{itemize}
    \item sporadic tasks with inter-arrival times that are event driven will not necessarily
      have device drivers which guarantee the inter-arrival time;
    \item the task may have an unknown or unreliable \gls{WCET};
    \item the system may be open and the task from an untrusted source;
    \item the task may be low criticality and therefore not certified to a high level.
\end{itemize}

The issue of trust in real-time literature has not been greatly addressed: real time tasks are often
assumed to perform correctly and safely.  However, much research has looked into the scheduling of
aperiodic tasks, which by definition do cannot be trusted to follow a specific schedule, or abide by
their estimated minimum inter-arrival time. Further applicable research examines the scheduling of
\gls{SRT} and best-effort tasks along with \gls{HRT} tasks. Consequently we examine scheduling methods for
these types of systems. 

Neither \gls{FP} nor \gls{EDF} scheduling
approaches discussed so far provides temporal isolation, although both can be adapted to do so.  In
this chapter we examine the techniques used by the real-time community to achieve temporal
isolation.

% TODO we should consider asymmetric protection here?
% TODO this sounds like it belongs in the chapter summary
%Temporal isolation requires tasks to specify their expected, or permitted temporal behaviour. This
%can be done by specifying a processor share, as in proportional share schedulers, or by using the
%period and execution requirement of the sporadic task model as an upper bound on task processor
%utilisation.

\section{Scheduling}

% TODO intro here

\subsection{Proportional share schedulers}
\label{s:pfair}

Proportional share schedulers provide temporal isolation, as long as the system is not overloaded,
although this class of schedulers is based on achieving scheduling fairness between tasks, rather
than running untrusted tasks which may exceed their execution requirement. 

Recall that fairness is not a central property of scheduling in an \gls{RTOS}. However, one approach
for real-time scheduling is to specify a set of constraints that attempt to provide fairness and
also satisfy temporal constraints.  These are referred to as \emph{proportional share} algorithms,
which allocate time to tasks in discrete sized quanta. Tasks in proportional share schedulers are assigned 
weights according to their rate, and those weights determine the share of time for which each task 
has access to a resource.

While proportional share algorithms are applied to many different scheduling problems, they apply
well to real-time scheduling on one or more processors.
Unlike other approaches to real-time scheduling, proportional share schedulers have the explicit property of guaranteeing a rate of progress for all tasks in the system.

\citet{Baruah_CPV_96} introduced the property \emph{proportionate fairness} or \emph{Pfair} as a
strong fairness property for proportionate share scheduling algorithms.  For a schedule to be Pfair,
then at every time $t$ a task $T$ with weight $T_{w}$ must have been scheduled either $\lceil T_{w}
. t \rceil$ or $\lfloor T_{w}.t \rfloor $ times.  \emph{Early-Release fair} or
ERfair~\citep{Anderson_Srinivasan_04} is an extension of the Pfair property that allows tasks to
execute before their Pfair window, which can allow for better response times.

Pfair scheduling algorithms break jobs into sub-jobs that match the length of a quantum.
Real-time and non-real time tasks are treated similarly.
When overload conditions exist, the rate is slowed for all tasks.

Pfair scheduling algorithms are good theoretically but do not perform well in practice; they incur
large overhead related capacity loss due to an increased number of context
switches~\citep{Abeni_Buttazzo_04}. Additionally, since
scheduling decisions can only be made at quantised intervals, scheduling is less precise in
proportionate fair systems.  This problem can be exacerbated by critical sections, which may last
longer than a single quantum.  \citet{Stoica_AKBGP_96} propose defining arbitrary quanta sizes based
on maximum critical section size, however quanta size decreases the accuracy of the scheduler.
Additionally, it may not be possible to have \emph{a priori} knowledge of critical section size, especially
in a soft real-time systems where it is not worth conducting \gls{WCET} analysis or execution time
is dependant on exterior factors, such as network behaviour.

One early uniprocessor Pfair scheduling algorithm is earliest eligible deadline first, presented in
\citet{Stoica_AKBGP_96}.  PD$^{2}$~\citep{Srinivasan_Anderson_06} is a more recent Pfair/ERfair
scheduling algorithm that is theoretically optimal for multiprocessors under \gls{HRT} constraints,
although only under the assumption that process preemption and migration are free.

Recall that temporal isolation means that tasks should not be able to interfere with the temporal
behaviour of other tasks in the system.  Proportionate fair systems provide temporal isolation as
part of their fairness property, unless the system is overloaded, at which point the rate of all
tasks will degrade. Pfair schedulers by definition do not support asymmetric protection.

\subsection{Isolation with EDF schedulers}

Temporal isolation in \gls{EDF} scheduling has been explored thoroughly in the real-time discipline.
We outline the most dominant approaches in this section.

\paragraph{Robust earliest deadline scheduling}
One early approach to temporal isolation with \gls{EDF} scheduling attempts to extend the 
algorithm to allow overload conditions to be handled with respect to a value. Robust earliest deadline
scheduling~\citep{Buttazzo_Stankovic_93} assigns a value to each task set, and drop jobs from
low-value tasks under overload. If the system returns to non-overload conditions those tasks are
scheduled again. This is a very early version of asymmetric protection
The algorithm is optimal, however this is only the case if
scheduler overhead is excluded.  Since the algorithm is has O($n$) complexity in the number of
tasks, the authors recommend using a dedicated scheduling processor such that overhead will not
effect the timing behaviour -- but this is not suitable for embedded systems, where the goal is to
minimise the number of processors, not increase them.

\paragraph{\Gls{CBS}} \citet{Abeni_Buttazzo_04} introduce a technique for scheduling \gls{HRT} and
\gls{SRT} tasks and providing temporal isolation.  \gls{HRT} tasks are scheduled using an \gls{EDF}
scheduler, but \gls{SRT} tasks are treated differently as \gls{EDF} does not handle overload.
Instead, a \gls{CBS} is assigned to each \gls{SRT} task.  Each \gls{CBS} has a bandwidth assigned to
it, and breaks down \gls{SRT} jobs into sub-jobs such that the utilisation rate of the task does not
exceed the assigned bandwidth.  Any sub-job that will cause the bandwidth to be exceeded is
postponed, but still executed.

\gls{CBS} stands out from previous server based approaches~\citep{Spuri_Buttazzo_96,
Ghazalie_Baker_95, Spuri_Buttazzo_94, Deng_Liu_97} as it does not require a \gls{WCET} or a minimum
bound on job inter-arrival time, making it much more suitable for \gls{SRT} tasks.  Implementation
wise, \gls{CBS} has fewer hardware overheads than Pfair schedulers.

Many extensions exist to \gls{CBS} to improve functionality.  \citet{Kato_IR_11} extend \gls{CBS} to
implement \emph{slack donation}, where any unused bandwidth is given to other jobs.  In
~\citep{Craciunas_KPRS_12}, \gls{CBS} is extended such that bandwidths are variable at run-time.
\citet{Lamastra_LA_01} introduce bandwidth inheritance across CBS servers applied to different
resources, providing temporal isolation for additional resources other than processing time.

\paragraph{\Gls{RBED}} schedulers explicitly separate the resource allocation and dispatching
(choosing which thread to run) in order to provide flexibility in timeliness requirements supported
by the scheduler.  \Gls{RBED} ~\citep{Brandt_BLB_03} is an algorithm that implements such a
scheduler.  In \gls{RBED}, tasks are considered as either \gls{HRT}, \gls{SRT}, best effort or
rate-based.  Tasks are modelled using an extension of the periodic task model, allowing any job of a
task to have a different period.  If rate-based or \gls{HRT} tasks cannot be scheduled at their
desired rate they are rejected.  \gls{SRT} tasks are given their rate if possible with the option to
provide a quality of service specification.  Processor time reservations can be used to make sure
best effort tasks are allowed some execution time.  Otherwise they are allocated slack time unused
by SRT and HRT tasks.  Either way, best effort tasks are scheduled by assigning them a rate that
reflects how they would be scheduled in a standard, fair, quantum-based scheduler.  Based on the
rates used, \gls{RBED} breaks tasks down and feeds them to an \gls{EDF} scheduler to manage
processing time.  Rates are enforced using a one-shot timer to stop tasks that exceed their
{\gls{WCET}}.  As tasks enter and leave the system, the rates of \gls{SRT} tasks will change.  Slack
time that occurs as a result of tasks completing before their deadlines is only donated to best
effort tasks, although the authors note that extensions should be able to donate slack to \gls{SRT}
tasks as well.  \Gls{RBED} is similar to the concept of CBS, however it deals with separate types of
real-time tasks more explicitly.

\subsection{Isolation with FP schedulers}
\label{background:fp-isolation}

While \gls{CBS} and \gls{RBED} provide temporal isolation for \gls{EDF} scheduling, we will now
examine methods for temporal isolation in fixed-priority systems, whilst maintaining compatibility
with rate-monotonic schedulability tests.  Like \gls{CBS}, tasks are constrained by encapsulating
one or more tasks in a server which prevents the task(s) from overrunning their assigned scheduling
parameters.

\paragraph{Polling servers}\label{p:polling-servers}~\citep{Lehoczky_LS_87} wake every period,
to check if there are any pending tasks, then runs them for maximum their budget time. If there is no
task to run, the polling server will go back to sleep. That is, at time $t_{i}$, if there are no
tasks ready to execute, the server will sleep until $t_{i+1}$. This has the limitation task latency
is a function of the period $T$.

\paragraph{Deferrable Servers}\label{p:ds} Unlike polling servers, \emph{deferrable
servers}\citep{Lehoczky_LS_87, Strosnider_LS_95} preserve any unused budget across periods, although
the budget can never be exceeded.  This removes latency problems with polling servers, but
unfortunately breaks rate-monotonic schedulability analysis, as this policy can result in servers
executing back-to-back and exceeding their allocated scheduling bandwidth for any specific occurrence of
the period.  This occurs as deferrable servers replenish the budget to full at the start of each
period, and the budget can be used at any point during a tasks execution. 

We demonstrate the problem with deferrable servers using the notation introduced in
\Cref{t:notation}. Consider a sporadic task with implicit deadlines in a task set, 
$A_{1}$, with jobs $A_{11}, A_{12}, ..., A_{1n}$. Each job in that task set has a deadline once the
period has passed: $d_{1j} = t_{1j} + T_{1}$. The problem occurs if the first job arrives at $a_{11}
= d_{11} - C_{1}$, such that it only completes at exactly the implicit deadline.  
Then a second job may arrive at the release time $d_{11}$ such that it runs back-to-back with the first
task, from $a_11$ to $d_{11} + C_{1}$, then the task has exceeded its permitted utilisation 
($\frac{C_{1}}{T_{1}})$. As a result deadline misses can be caused in other
tasks, violating temporal isolation.

\paragraph{Sporadic servers}~\citep{Sprunt_SL_89a}\label{p:sporadic} address the problems of
deferrable servers by scheduling multiple replenishment times, in order to preserve the property
that for all possible points in time $U_{i} \leq \frac{C_{i}}{T_{i}}$, known as the \emph{sliding window} constraint, which
is the condition that deferrable servers violate.  Each time a task is preempted, or blocks, a
replenishment is set for current time + $T_{i}$, for the amount consumed.  When no replenishments are
available, sporadic servers have their priority decreased below any real-time task.  The priority is
restored once a replenishment is available.  While this addresses the problems of deferrable
servers, the implementation is problematic as the number of times a thread is preempted or blocked
is potentially unbounded.  It is also subject to capacity loss as tasks that use very small chunks
of budget at a time increase the interrupt load.  The bigger the bound on replenishments the less
accurate the sporadic server, but the more memory used resulting in degraded performance.

\paragraph{Priority exchange servers}~\citep{Sprunt_SL_89a} swap the priority of an inactive
aperiodic task with a periodic task, such that server capacity is not lost but used at a lower
priority.  Implementations of priority exchange require control and access to priorities across an
entire system.

\paragraph{Slack stealing}~\citep{Ramos_Thuel_Lehoczky_93} is an approach that runs a scheduling
task at the lowest priority and tracks the amount of slack per task in the system.  As aperiodic
tasks arrive, the slack stealer calculates whether they can be scheduled or not based on the slack
in the system and current load of periodic tasks.  This method does not provide guarantees at all
for the aperiodic tasks, unless a certain bound is placed on the execution of periodic tasks.

\section{Mixed-criticality schedulers}

In this section, we briefly consider schedulers designed specifically for mixed-criticality systems. 
However, as this has been a very active topic, we refer the reader to \citet{Burns_Davis_17} for
an extensive background. 

Temporal isolation in mixed-criticality systems can result in \emph{criticality inversion}, where
high criticality tasks miss their deadlines due to lower criticality tasks.  Rather than temporal
isolation, mixed-criticality systems require \emph{asymmetric protection}, where deadline misses of
low-criticality tasks caused by high-criticality tasks are permitted, but not vice-versa.  This can
be realised as a system mode-switch or form of graceful degradation.

A key observation about mixed-criticality systems is neither the strictness of the real-time model,
nor rate-monotonic priorities have any direct correlation with the criticality of a task.  While in
general critical tasks are \gls{HRT}, it is possible to have critical tasks that are \gls{SRT}, for
instance, object tracking algorithms whose \gls{WCET} depends on factors external to the software
system.

None of the scheduling algorithms so far directly support mixed-criticality systems.  \gls{RBED} is
the closest, although it assumes a direct relationship between criticality and real-time model, with
the assumption that \gls{HRT} tasks are more critical than \gls{SRT} tasks which are more critical
than best effort tasks. 

Recall that in this model \glspl{CA} provide \gls{WCET} estimates that must be schedulable, however they are often very
pessimistic.  This results in a task with two {\gls{WCET}} estimates, one very pessimistic one from
the \gls{CA} and a less pessimistic one from the system designers or automated tools.  As a result
of this, a family of mixed-criticality schedulers exists that handle high criticality tasks with two
{\gls{WCET}} estimates, and low-criticality tasks.  The scheduling algorithm will always schedule
high-criticality tasks.  If high-criticality tasks finish before the lower \gls{WCET} estimate,
lower criticality tasks are also scheduled.  Otherwise, tasks of lower criticality may not be
scheduled at all. 

Schedulers in this class are distinguished by a mode-switch between two or more criticality levels,
which may result in low criticality tasks being dropped or de-prioritised in some way. 
Schedulers for this model of mixed-criticality have been developed and extensively studied for
\gls{FP}~\citet{Vestal_07, Pathan:phd}, \gls{EDF}~\citet{Baruah_BDMVS_11},

\subsection{Zero Slack Scheduling}

\Citet{deNiz_LR_09} propose a scheduling approach that can handle multiple levels of criticality,
called \gls{ZS} scheduling. \gls{ZS} scheduling is based on the fact that tasks rarely use their
\gls{WCET}.  This means that resource reservation techniques like \gls{CBS} without slack donation
result in low effective utilisation.  ZS scheduling takes the reverse approach: high criticality
tasks steal utilization from lower criticality tasks.  This involves calculating a \gls{ZS} instant
- the last point at which a task can be scheduled without missing its deadline.  Under overload, the
\gls{ZS} scheduler makes sure that high criticality tasks are scheduled by their \gls{ZS} instant,
such that they cannot be preempted by lower criticality tasks.

Implementations of \gls{ZS} scheduling can be built using any priority-based scheduling technique,
however in the initial work \gls{FP} with \gls{RM} priority assignment is used.  The
\gls{ZS}\gls{RM} scheduler is proven to be able to schedule anything that standard \gls{RM}
scheduling can, whilst maintaining the asymmetric protection property.  \gls{ZS} scheduling can be
combined with temporal isolation via bandwidth servers.

% TODO possible rewrite
\gls{ZS} scheduling has been adapted to use a \gls{QoS} based resource allocation
model~\citep{deNiz_WSRR_12}, in the context of \glspl{UAV}.  Many models of real-time systems assume
that \glspl{WCET} for real-time tasks are stable and can be calculated.  However, \glspl{UAV} have
complicated visual object tracking algorithms where \gls{WCET} is difficult to calculate, and
execution time varies with the number of objects to track.  In practice, \Citet{deNiz_WSRR_12} found
that \gls{ZS}\gls{RM} scheduling resulted in \emph{utility inversion} --- where lower utility tasks
prevent the execution of higher utility tasks.  Although assuring no criticality inversion occurred
with a criticality based approach, under overload, some tasks offer more utility than others with
increased execution time.  As a result, the authors replace criticality in the algorithm with a
utility function.  Two execution time estimates are used for real-time tasks --- \gls{NCET} and
\gls{OCET}, each having their own utility.  The goal of the scheduler is to maximise utility, under
normal operation and overload.

\section{Resource sharing}

Like the scheduling algorithms, the locking protocols presented in
\Cref{sec:resource-sharing-theory} do not work if tasks are untrusted: in all of the protocols, if a
task does not voluntarily release the resource, all other tasks sharing that resource will be
blocked.

One of our goals is to allow tasks of different criticality to share resources.  While the resource
itself must be at the highest criticality of systems using it, this relationship need not be
symmetric; low criticality systems should be able to use high criticality resources.

In this section we explore how resource reservations and real-time locking protocols interact, and
asses their suitability for mixed criticality systems.  As introduced in
\cref{sec:resource-kernels}, when combining locking protocols and reservations one must consider
prioritisation, charging and enforcement.

Prioritisation, or what priority a task uses while accessing a resource, can be decided by any of
the existing protocols: \gls{PCP}, \gls{HLP} or \gls{PIP}, \gls{SRP}. Which reservation to charge 
for processing time consumed when accessing a shared resource, and when to charge, are more
interesting. \citet{deNiz_LSR_01} describe the possible mappings
between reservations and resources consuming those reservations, which comes down to the following
choices:

\begin{description}
\item[Bandwidth inheritance] Tasks using the resource run on their own reservation.  If that
    reservation expires and their are other pending tasks, the task runs on the reservations of the
    pending tasks. 
\item[Reservation for the resource] Shared resources have their own reservation, which tasks use.
    This reservation must be enough for all tasks to complete their request.  Once again, if tasks
    are untrusted no temporal isolation is provided. 
\item[Multi-reserve resources] Shared resources have multiple reservations, and the resource
    actively switches between them depending on which task it is servicing. 
\end{description} 

Of most relevant to mixed-criticality systems, where tasks cannot be guaranteed to unlock a
resource, is the enforcement mechanism.  Many protocols rely on tasks being trusted with \emph{a
priori} knowledge of a tasks resource usage.  However, in systems where tasks may not be trusted
(either due to security, certification level, or potential bugs) such \emph{a priori}
knowledge is unavailable. 

\citet{Brandenburg_14} outlines a multiprocessor \gls{IPC} based protocol where shared resources are placed in
resource servers accessed. In this scheme, the resources themselves must be at the ceiling
criticality of any task accessing those resources, but all tasks do not have to be at that
criticality level. The protocol works by channelling all IPC requests through a three-level,
multi-ended queue where high criticality tasks are prioritised over best effort tasks. 

\section{Summary}

%TODO{rewrite to include whole chapter}

Traditional scheduling algorithms, like \gls{EDF} and \gls{FP}-\gls{RM} schedule processor time but do not consider criticality differences between tasks, and also trust all tasks to stay within their \gls{WCET}.
Due to pessimism in \gls{WCET} estimates, this results in low utilisation in such systems and also prevents systems of mixed-criticality being constructed in a safe way.

Mixed-criticality systems require at minimum temporal isolation, however the asymmetric protection property allows for higher utilisation in systems.
\gls{EDF} and \gls{FP} scheduling can be adapted to have temporal isolation, or another approach, like PFair scheduling can be used to provide temporal isolation.
Much research has been done into scheduling algorithms that provide asymmetric protection, but the consequences of practical implementations in \glspl{OS} have yet to be explored.

In the next chapter, we survey existing operating systems and systems techniques with respect to temporal isolation capability, resource sharing, and asymmetric protection.

